{"cells":[{"cell_type":"code","metadata":{"id":"TCHw6F7Vw9Q_","source_hash":null,"execution_start":1703903705181,"execution_millis":759,"deepnote_to_be_reexecuted":false,"cell_id":"b591d6d43f2542c08046d5cbae2b72f8","deepnote_cell_type":"code"},"source":"import time\nfrom random import random\n\nimport numpy as np\nfrom pydrake.all import (\n    DiagramBuilder,\n    MeshcatVisualizer,\n    MultibodyPlant,\n    Parser,\n    RigidTransform,\n    RollPitchYaw,\n    RotationMatrix,\n    SolutionResult,\n    Solve,\n    StartMeshcat,\n)\nfrom pydrake.multibody import inverse_kinematics\n\nfrom manipulation import running_as_notebook\nfrom manipulation.exercises.trajectories.rrt_planner.robot import (\n    ConfigurationSpace,\n    Range,\n)\nfrom manipulation.exercises.trajectories.rrt_planner.rrt_planning import Problem\nfrom manipulation.meshcat_utils import AddMeshcatTriad\nfrom manipulation.scenarios import MakeManipulationStation","block_group":"fd6f7b71116c422783605db6391acb38","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703903705937,"execution_millis":39,"deepnote_to_be_reexecuted":false,"cell_id":"9d355935d2444cc2ba69b90afc6b34dc","deepnote_cell_type":"code"},"source":"# Start the visualizer.\nmeshcat = StartMeshcat()","block_group":"3575c4d8063741159b64868b2d7b1163","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:drake:Meshcat listening for connections at https://06109659-1ce1-4127-8d4c-0eb734b835d4.deepnoteproject.com/7001/\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Meshcat URL: <a href='https://06109659-1ce1-4127-8d4c-0eb734b835d4.deepnoteproject.com/7001/' target='_blank'>https://06109659-1ce1-4127-8d4c-0eb734b835d4.deepnoteproject.com/7001/</a>"},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703903705991,"execution_millis":27,"deepnote_to_be_reexecuted":false,"cell_id":"7848b2d31d164dce86d4e1582afa7b68","deepnote_cell_type":"code"},"source":"class ManipulationStationSim:\n    def __init__(self, is_visualizing=False):\n        builder = DiagramBuilder()\n        self.station = builder.AddSystem(\n            MakeManipulationStation(\n                filename=\"package://manipulation/manipulation_station_with_cupboard.dmd.yaml\",\n                time_step=1e-3,\n            )\n        )\n        self.plant = self.station.GetSubsystemByName(\"plant\")\n        self.scene_graph = self.station.GetSubsystemByName(\"scene_graph\")\n        self.is_visualizing = is_visualizing\n\n        # scene graph query output port.\n        self.query_output_port = self.scene_graph.GetOutputPort(\"query\")\n\n        # meshcat visualizer\n        if is_visualizing:\n            self.viz = MeshcatVisualizer.AddToBuilder(\n                builder, self.station.GetOutputPort(\"query_object\"), meshcat\n            )\n\n        self.diagram = builder.Build()\n\n        # contexts\n        self.context_diagram = self.diagram.CreateDefaultContext()\n        self.context_station = self.diagram.GetSubsystemContext(\n            self.station, self.context_diagram\n        )\n        self.context_scene_graph = self.station.GetSubsystemContext(\n            self.scene_graph, self.context_station\n        )\n        self.context_plant = self.station.GetMutableSubsystemContext(\n            self.plant, self.context_station\n        )\n        # mark initial configuration\n        self.q0 = self.plant.GetPositions(\n            self.context_plant, self.plant.GetModelInstanceByName(\"iiwa\")\n        )\n        if is_visualizing:\n            self.DrawStation(self.q0, 0.1, -np.pi / 2, np.pi / 2)\n\n    def SetStationConfiguration(\n        self, q_iiwa, gripper_setpoint, left_door_angle, right_door_angle\n    ):\n        \"\"\"\n        :param q_iiwa: (7,) numpy array, joint angle of robots in radian.\n        :param gripper_setpoint: float, gripper opening distance in meters.\n        :param left_door_angle: float, left door hinge angle, \\in [0, pi/2].\n        :param right_door_angle: float, right door hinge angle, \\in [0, pi/2].\n        :return:\n        \"\"\"\n        self.plant.SetPositions(\n            self.context_plant,\n            self.plant.GetModelInstanceByName(\"iiwa\"),\n            q_iiwa,\n        )\n        self.plant.SetPositions(\n            self.context_plant,\n            self.plant.GetModelInstanceByName(\"wsg\"),\n            [-gripper_setpoint / 2, gripper_setpoint / 2],\n        )\n\n        # cabinet doors\n        if left_door_angle > 0:\n            left_door_angle *= -1\n        left_hinge_joint = self.plant.GetJointByName(\"left_door_hinge\")\n        left_hinge_joint.set_angle(context=self.context_plant, angle=left_door_angle)\n\n        right_hinge_joint = self.plant.GetJointByName(\"right_door_hinge\")\n        right_hinge_joint.set_angle(context=self.context_plant, angle=right_door_angle)\n\n    def DrawStation(self, q_iiwa, gripper_setpoint, q_door_left, q_door_right):\n        if not self.is_visualizing:\n            print(\"collision checker is not initialized with visualization.\")\n            return\n        self.SetStationConfiguration(\n            q_iiwa, gripper_setpoint, q_door_left, q_door_right\n        )\n        self.diagram.ForcedPublish(self.context_diagram)\n\n    def ExistsCollision(self, q_iiwa, gripper_setpoint, q_door_left, q_door_right):\n        self.SetStationConfiguration(\n            q_iiwa, gripper_setpoint, q_door_left, q_door_right\n        )\n        query_object = self.query_output_port.Eval(self.context_scene_graph)\n        collision_paris = query_object.ComputePointPairPenetration()\n\n        return len(collision_paris) > 0\n\n\nclass IiwaProblem(Problem):\n    def __init__(\n        self,\n        q_start: np.array,\n        q_goal: np.array,\n        gripper_setpoint: float,\n        left_door_angle: float,\n        right_door_angle: float,\n        is_visualizing=False,\n    ):\n        self.gripper_setpoint = gripper_setpoint\n        self.left_door_angle = left_door_angle\n        self.right_door_angle = right_door_angle\n        self.is_visualizing = is_visualizing\n\n        self.collision_checker = ManipulationStationSim(is_visualizing=is_visualizing)\n\n        # Construct configuration space for IIWA.\n        plant = self.collision_checker.plant\n        nq = 7\n        joint_limits = np.zeros((nq, 2))\n        for i in range(nq):\n            joint = plant.GetJointByName(\"iiwa_joint_%i\" % (i + 1))\n            joint_limits[i, 0] = joint.position_lower_limits()\n            joint_limits[i, 1] = joint.position_upper_limits()\n\n        range_list = []\n        for joint_limit in joint_limits:\n            range_list.append(Range(joint_limit[0], joint_limit[1]))\n\n        def l2_distance(q: tuple):\n            sum = 0\n            for q_i in q:\n                sum += q_i**2\n            return np.sqrt(sum)\n\n        max_steps = nq * [np.pi / 180 * 2]  # three degrees\n        cspace_iiwa = ConfigurationSpace(range_list, l2_distance, max_steps)\n\n        # Call base class constructor.\n        Problem.__init__(\n            self,\n            x=10,  # not used.\n            y=10,  # not used.\n            robot=None,  # not used.\n            obstacles=None,  # not used.\n            start=tuple(q_start),\n            goal=tuple(q_goal),\n            cspace=cspace_iiwa,\n        )\n\n    def collide(self, configuration):\n        q = np.array(configuration)\n        return self.collision_checker.ExistsCollision(\n            q,\n            self.gripper_setpoint,\n            self.left_door_angle,\n            self.right_door_angle,\n        )\n\n    def visualize_path(self, path):\n        if path is not None:\n            # show path in meshcat\n            for q in path:\n                q = np.array(q)\n                self.collision_checker.DrawStation(\n                    q,\n                    self.gripper_setpoint,\n                    self.left_door_angle,\n                    self.right_door_angle,\n                )\n                if running_as_notebook:\n                    time.sleep(0.2)\n\n\nclass IKSolver(object):\n    def __init__(self):\n        ## setup controller plant\n        plant_iiwa = MultibodyPlant(0.0)\n        iiwa_file = \"package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf\"\n        iiwa = Parser(plant_iiwa).AddModelsFromUrl(iiwa_file)[0]\n        # Define frames\n        world_frame = plant_iiwa.world_frame()\n        L0 = plant_iiwa.GetFrameByName(\"iiwa_link_0\")\n        l7_frame = plant_iiwa.GetFrameByName(\"iiwa_link_7\")\n        plant_iiwa.WeldFrames(world_frame, L0)\n        plant_iiwa.Finalize()\n        plant_context = plant_iiwa.CreateDefaultContext()\n\n        # gripper in link 7 frame\n        X_L7G = RigidTransform(\n            rpy=RollPitchYaw([np.pi / 2, 0, np.pi / 2]), p=[0, 0, 0.114]\n        )\n        world_frame = plant_iiwa.world_frame()\n\n        self.world_frame = world_frame\n        self.l7_frame = l7_frame\n        self.plant_iiwa = plant_iiwa\n        self.plant_context = plant_context\n        self.X_L7G = X_L7G\n\n    def solve(self, X_WT, q_guess=None, theta_bound=0.01, position_bound=0.01):\n        \"\"\"\n        plant: a mini plant only consists of iiwa arm with no gripper attached\n        X_WT: transform of target frame in world frame\n        q_guess: a guess on the joint state sol\n        \"\"\"\n        plant = self.plant_iiwa\n        l7_frame = self.l7_frame\n        X_L7G = self.X_L7G\n        world_frame = self.world_frame\n\n        R_WT = X_WT.rotation()\n        p_WT = X_WT.translation()\n\n        if q_guess is None:\n            q_guess = np.zeros(7)\n\n        ik_instance = inverse_kinematics.InverseKinematics(plant)\n        # align frame A to frame B\n        ik_instance.AddOrientationConstraint(\n            frameAbar=l7_frame,\n            R_AbarA=X_L7G.rotation(),\n            #   R_AbarA=RotationMatrix(), # for link 7\n            frameBbar=world_frame,\n            R_BbarB=R_WT,\n            theta_bound=position_bound,\n        )\n        # align point Q in frame B to the bounding box in frame A\n        ik_instance.AddPositionConstraint(\n            frameB=l7_frame,\n            p_BQ=X_L7G.translation(),\n            # p_BQ=[0,0,0], # for link 7\n            frameA=world_frame,\n            p_AQ_lower=p_WT - position_bound,\n            p_AQ_upper=p_WT + position_bound,\n        )\n        prog = ik_instance.prog()\n        prog.SetInitialGuess(ik_instance.q(), q_guess)\n        result = Solve(prog)\n        if result.get_solution_result() != SolutionResult.kSolutionFound:\n            return result.GetSolution(ik_instance.q()), False\n        return result.GetSolution(ik_instance.q()), True\n\n\nclass TreeNode:\n    def __init__(self, value, parent=None):\n        self.value = value  # tuple of floats representing a configuration\n        self.parent = parent  # another TreeNode\n        self.children = []  # list of TreeNodes\n\n\nclass RRT:\n    \"\"\"\n    RRT Tree.\n    \"\"\"\n\n    def __init__(self, root: TreeNode, cspace: ConfigurationSpace):\n        self.root = root  # root TreeNode\n        self.cspace = cspace  # robot.ConfigurationSpace\n        self.size = 1  # int length of path\n        self.max_recursion = 1000  # int length of longest possible path\n\n    def add_configuration(self, parent_node, child_value):\n        child_node = TreeNode(child_value, parent_node)\n        parent_node.children.append(child_node)\n        self.size += 1\n        return child_node\n\n    # Brute force nearest, handles general distance functions\n    def nearest(self, configuration):\n        \"\"\"\n        Finds the nearest node by distance to configuration in the\n             configuration space.\n\n        Args:\n            configuration: tuple of floats representing a configuration of a\n                robot\n\n        Returns:\n            closest: TreeNode. the closest node in the configuration space\n                to configuration\n            distance: float. distance from configuration to closest\n        \"\"\"\n        assert self.cspace.valid_configuration(configuration)\n\n        def recur(node, depth=0):\n            closest, distance = node, self.cspace.distance(node.value, configuration)\n            if depth < self.max_recursion:\n                for child in node.children:\n                    (child_closest, child_distance) = recur(child, depth + 1)\n                    if child_distance < distance:\n                        closest = child_closest\n                        child_distance = child_distance\n            return closest, distance\n\n        return recur(self.root)[0]","block_group":"8f32cba0f4f64b7c9741d5b1fb4d350d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wJxE0ZSgxDFl","cell_id":"04ca76775fa64806815c55d972bf9df7","deepnote_cell_type":"markdown"},"source":"# RRT Motion Planning\n\nIn the lectures on motion planning, you are introduced to optimization-based motion planning and sampling-based motion planning. In this exercise, you will first implement the famous Rapidly-exploring Random Tree (RRT) algorithm. Next, you will reflect on the properties of the RRT algorithm. A 2D visualization of the RRT algorithm is shown below. ","block_group":"2c391cd9ed7e435d98c161120b9b366b"},{"cell_type":"code","metadata":{"id":"ssfgBwB3x2yc","source_hash":null,"execution_start":1703903706062,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"1ddcbded10a746409da1cf2585b82161","deepnote_cell_type":"code"},"source":"from IPython.display import Image\n\nImage(\n    url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif/450px-Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif\"\n)","block_group":"326c9b60d8d949ceb5ee92a226545783","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/html":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif/450px-Rapidly-exploring_Random_Tree_%28RRT%29_500x373.gif\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"YkAeqwCHydaP","cell_id":"078e37e737a54455a27560aa7c8c54ba","deepnote_cell_type":"markdown"},"source":"Let's first generate a problem instance. Let's use the default initial joint state as our starting configuration $q_{start}$. Let's use a pre-defined frame in 3D world as our goal pose. The frame of the goal pose can be viewed in the meshcat visualizer below. ","block_group":"62bccaf066aa4a028fbbdaea8118043b"},{"cell_type":"code","metadata":{"id":"IRzTg8bdw9RF","source_hash":null,"execution_start":1703903797078,"execution_millis":648,"deepnote_to_be_reexecuted":false,"cell_id":"3cdfdc83e5124495ab7f2dbd17d34d34","deepnote_cell_type":"code"},"source":"env = ManipulationStationSim(True)\nq_start = env.q0\nR_WG = RotationMatrix(np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]]).T)\nT_WG_goal = RigidTransform(p=np.array([4.69565839e-01, 2.95894043e-16, 0.65]), R=R_WG)\nAddMeshcatTriad(meshcat, \"goal pose\", X_PT=T_WG_goal, opacity=0.5)","block_group":"312c3afb38da485ba8126c92fd58f32c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHj1mtAuzP1F","cell_id":"e4889b86e0ef4bb69c233075c490a5ff","deepnote_cell_type":"markdown"},"source":"The joint states of the goal pose can be computed via inverse kinematics.","block_group":"11cb5ca1adc34e099e12c08e6134d171"},{"cell_type":"code","metadata":{"id":"0v_4tS_xw9RL","source_hash":null,"execution_start":1703903812292,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"b718821e981d4208ba099f5a4c8eb3fb","deepnote_cell_type":"code"},"source":"ik_solver = IKSolver()\nq_goal, optimal = ik_solver.solve(T_WG_goal, q_guess=q_start)","block_group":"41717fb0531c4cdb92364428d8a981d0","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_iPAypZPzgQd","cell_id":"21dc88f8def14b2393ae94414338625a","deepnote_cell_type":"markdown"},"source":"Given the start and goal states, we now have sufficient information to formulate the pathfinding problem. We use `IiwaProblem` class to store all relevant information about the pathfinding problem. For this exercise, you don't have to know the details of this class.","block_group":"c3681dd8f45543dfb87bccce4ef9ca39"},{"cell_type":"code","metadata":{"id":"exkFjk8jw9RP","source_hash":null,"execution_start":1703903708428,"execution_millis":672,"deepnote_to_be_reexecuted":false,"cell_id":"3e29bddff42246f18a0604c1125e76a8","deepnote_cell_type":"code"},"source":"gripper_setpoint = 0.1\ndoor_angle = np.pi / 2 - 0.001\nleft_door_angle = -np.pi / 2\nright_door_angle = np.pi / 2\n\niiwa_problem = IiwaProblem(\n    q_start=q_start,\n    q_goal=q_goal,\n    gripper_setpoint=gripper_setpoint,\n    left_door_angle=left_door_angle,\n    right_door_angle=right_door_angle,\n    is_visualizing=True,\n)","block_group":"7774d5a4f58f4e118bbf4249f8be3099","execution_count":null,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_514/1299876036.py:115: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  joint_limits[i, 0] = joint.position_lower_limits()\n/tmp/ipykernel_514/1299876036.py:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  joint_limits[i, 1] = joint.position_upper_limits()\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"njvk8Yim0AF7","cell_id":"ac5ef2e41cfd46329af7da03003c2299","deepnote_cell_type":"markdown"},"source":"# RRT Algorithm\n\nAn RRT grows a tree rooted at the starting configuration by using random samples from the search space. As each sample is drawn, a connection is attempted between it and the nearest state in the tree. If the connection is feasible (passes entirely through free space and obeys any constraints), this results in the addition of the new state to the tree.\n\nWith uniform sampling of the search space, the probability of expanding an existing state is proportional to the size of its Voronoi region. As the largest Voronoi regions belong to the states on the frontier of the search, this means that the tree preferentially expands towards large unsearched areas.\n\nHowever, it may be useful sometimes to bias our exploration towards the goal. In that case, one can artificially set a probability to use the value of the goal as the next sample. \n\nThe pseudocode of the RRT algorithm is shown below.","block_group":"58a54bd4e3e34a1c9a856cf5f74a5afe"},{"cell_type":"markdown","metadata":{"id":"GDLn7bfYw9RT","cell_id":"c982773d44ae40949b266c598ea1f9ef","deepnote_cell_type":"markdown"},"source":"  **Algorithm RRT**\n    \n      Input: q_start, q_goal, max_interation, prob_sample_goal\n      Output: path\n\n      G.init(q_start)\n      for k = 1 to max_interation:\n        q_sample ← Generate Random Configuration\n        random number ← random()\n        if random_number < prob_sample_goal:\n            q_sample ← q_goal\n        n_near ← Find the nearest node in the tree(q_sample)\n        (q_1, q_2, ... q_N) ← Find intermediate q's from n_near to q_sample\n        \n        // iteratively add the new nodes to the tree to form a new edge\n        last_node ← n_near\n        for n = 1 to N:\n            last_node ← Grow RRT tree (parent_node, q_{n}) \n        \n        if last node reaches the goal:\n            path ← backup the path recursively\n            return path\n        \n      return None","block_group":"f1ed828804634217ac70c46784131e21"},{"cell_type":"markdown","metadata":{"id":"drJRhESa3VIM","cell_id":"c5deef83a94449818e5814e295802425","deepnote_cell_type":"markdown"},"source":"Implementing RRT from scratch can be very time-consuming. Below, we have provided you the important features you will need to implement the RRT algorithm. Note that in `RRT_tools`, a robot configuration is referred to as $q$, whereas a node in the RRT tree is referred to as a node. One can access the configuration of a node by \n```\nq_sample = node.value\n```","block_group":"0e8588ae52c742bdaff3f2acdbc580a9"},{"cell_type":"code","metadata":{"id":"lrYX6hxsw9RU","source_hash":null,"execution_start":1703903709104,"execution_millis":39,"deepnote_to_be_reexecuted":false,"cell_id":"3aeb832f99f54a4d815367dd1cbf2627","deepnote_cell_type":"code"},"source":"class RRT_tools:\n    def __init__(self, problem):\n        # rrt is a tree\n        self.rrt_tree = RRT(TreeNode(problem.start), problem.cspace)\n        problem.rrts = [self.rrt_tree]\n        self.problem = problem\n\n    def find_nearest_node_in_RRT_graph(self, q_sample):\n        nearest_node = self.rrt_tree.nearest(q_sample)\n        return nearest_node\n\n    def sample_node_in_configuration_space(self):\n        q_sample = self.problem.cspace.sample()\n        return q_sample\n\n    def calc_intermediate_qs_wo_collision(self, q_start, q_end):\n        \"\"\"create more samples by linear interpolation from q_start\n        to q_end. Return all samples that are not in collision\n\n        Example interpolated path:\n        q_start, qa, qb, (Obstacle), qc , q_end\n        returns >>> q_start, qa, qb\n        \"\"\"\n        return self.problem.safe_path(q_start, q_end)\n\n    def grow_rrt_tree(self, parent_node, q_sample):\n        \"\"\"\n        add q_sample to the rrt tree as a child of the parent node\n        returns the rrt tree node generated from q_sample\n        \"\"\"\n        child_node = self.rrt_tree.add_configuration(parent_node, q_sample)\n        return child_node\n\n    def node_reaches_goal(self, node):\n        return node.value == self.problem.goal\n\n    def backup_path_from_node(self, node):\n        path = [node.value]\n        while node.parent is not None:\n            node = node.parent\n            path.append(node.value)\n        path.reverse()\n        return path","block_group":"0d87b5124a6f4e8787a4c9449296cf19","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lsRzky8W4nfb","cell_id":"3c90e205ffb6486284f6fcc6dbcf5068","deepnote_cell_type":"markdown"},"source":"## Implement RRT\n\n**(a) Implement the RRT algorithm below. You may find it significantly easier to use the `RRT_tools`.** \nIn your implementation, you may plan in either configuration space or task space. The provided `RRT_tools` is only for planning in the configuration space. Your implementation will be graded on whether the last node of the path has reached the goal.","block_group":"aafabf9d28bc4ed78ad44a1cb94180b8"},{"cell_type":"code","metadata":{"id":"YcvgX_B9w9RY","source_hash":null,"execution_start":1703904874360,"execution_millis":29,"deepnote_to_be_reexecuted":false,"cell_id":"079326fb8b3b449585f3c6e0e2fc32a4","deepnote_cell_type":"code"},"source":"def rrt_planning(problem, max_iterations=1000, prob_sample_q_goal=0.05):\n    \"\"\"\n    Input:\n        problem (IiwaProblem): instance of a utility class\n        max_iterations: the maximum number of samples to be collected\n        prob_sample_q_goal: the probability of sampling q_goal\n\n    Output:\n        path (list): [q_start, ...., q_goal].\n                    Note q's are configurations, not RRT nodes\n    \"\"\"\n    for iter in range(max_iterations):\n        rrt_tools = RRT_tools(iiwa_problem)\n        q_goal = problem.goal\n        q_start = problem.start\n        q_sample = rrt_tools.sample_node_in_configuration_space()\n        if random() < prob_sample_q_goal:\n            q_sample = q_goal\n        n_near = rrt_tools.find_nearest_node_in_RRT_graph(q_sample)\n        safe_path = rrt_tools.calc_intermediate_qs_wo_collision(n_near.value, q_sample)\n        last_node = n_near\n        for i in range(len(safe_path)):\n            last_node = rrt_tools.grow_rrt_tree(last_node, safe_path[i])\n        if rrt_tools.node_reaches_goal(last_node):\n            path = rrt_tools.backup_path_from_node(last_node)\n            return path\n\n    return None","block_group":"4570434a36054b6ab9ab4e187f76d961","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3ZOEcE9w9Rh","source_hash":null,"execution_start":1703904876158,"execution_millis":151,"deepnote_to_be_reexecuted":false,"cell_id":"85ab9880f56e4b569636772f7171f0b6","deepnote_cell_type":"code"},"source":"path = rrt_planning(iiwa_problem, 600, 0.05)","block_group":"05c36f9237964f649d85fc85b4ed55d0","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d852c3Oa5IVF","cell_id":"451c2c18dded40e7a831d31f6dc5c197","deepnote_cell_type":"markdown"},"source":"You may step through the waypoints of the planned path below.","block_group":"4ce092a63a9043a4b461b7628fc5d348"},{"cell_type":"code","metadata":{"id":"Gd7CC-3Cw9Rm","source_hash":null,"execution_start":1703904881949,"execution_millis":7032,"deepnote_to_be_reexecuted":false,"cell_id":"b60f1e0afb4a4f689739c3665b9f0f9a","deepnote_cell_type":"code"},"source":"iiwa_problem.visualize_path(path)","block_group":"33e2741b93ff4144a39b5da70559c1e9","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMhnEoWWw9Rp","cell_id":"271350cd59974b61973abac9cbed8bbf","deepnote_cell_type":"markdown"},"source":"**Answer the following question regarding the properties of the RRT algorithm**\n\n(b) Consider the case where we let our RRT algorithm run forever, i..e max_iterations is set to $\\infty$. If there is no path to the goal, will RRT warn you? If there is a path to the goal, will RRT eventually find that path? Explain your reasoning for both cases. \n\n> RRT won't warn us because it just keeps growing the tree with a naive implementation. If there is a path, RRT will eventually find that path because it can cover all cspace. It is complete.\n","block_group":"b755ca64ea8048a8a7eb7a40f0485c84"},{"cell_type":"markdown","metadata":{"id":"MwE8yNg58VQN","cell_id":"1ed7967d06774facb947c3a29e21fb05","deepnote_cell_type":"markdown"},"source":"## How will this notebook be Graded?\n\nIf you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n\nFor submission of this assignment, you must do two things. \n- Download and submit the notebook `rrt_planning.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n- Write down your answers to 6.2.b in your PDF submission to Gradescope. \n\nWe will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n- [5 pts] Correct Implementation of `rrt_planning` method.\n- [3 pts] Reasonable answers and explanations for part (b) ","block_group":"8429fe7ab1824bbabe9b1ab07551abf7"},{"cell_type":"code","metadata":{"id":"XjQh6E-r_CNx","source_hash":null,"execution_start":1703905139126,"execution_millis":1925,"deepnote_to_be_reexecuted":false,"cell_id":"74c51fa2fd44448f9aa0f4a634395676","deepnote_cell_type":"code"},"source":"from manipulation.exercises.grader import Grader\nfrom manipulation.exercises.trajectories.test_rrt_planning import TestRRT\n\nGrader.grade_output([TestRRT], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"cd46dc7bd81a4bab905254355a6cf144","execution_count":null,"outputs":[{"name":"stdout","text":"Total score is 5/5.\n\nScore for Test RRT Planner is 5/5.\n- Constructed problem object\nStarted to solve the problem using RRT planner ...\nrun 1 found a solution\n/tmp/ipykernel_514/1299876036.py:115: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  joint_limits[i, 0] = joint.position_lower_limits()\n/tmp/ipykernel_514/1299876036.py:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  joint_limits[i, 1] = joint.position_upper_limits()\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=06109659-1ce1-4127-8d4c-0eb734b835d4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rrt_planning.ipynb","provenance":[],"collapsed_sections":["GC4aZuODw9Q9"]},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3.8.10 64-bit"},"celltoolbar":"Tags","language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"b2d0051644484ad99b2ff39941c52af6","deepnote_execution_queue":[]}}
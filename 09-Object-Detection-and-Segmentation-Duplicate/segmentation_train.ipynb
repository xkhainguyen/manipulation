{"cells":[{"cell_type":"markdown","metadata":{"id":"DfPPQ6ztJhv4","cell_id":"bbaa644764a3407e940ffdb97eeaa81d","deepnote_cell_type":"markdown"},"source":"# Mask R-CNN for Bin Picking\n\nThis notebook is adopted from the [TorchVision 0.3 Object Detection finetuning tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html).  We will be finetuning a pre-trained [Mask R-CNN](https://arxiv.org/abs/1703.06870) model on a dataset generated from our \"clutter generator\" script.\n","block_group":"10c005045c044c0a8d4e8d5caeefa6ee"},{"cell_type":"code","metadata":{"id":"DBIoe_tHTQgV","source_hash":null,"execution_start":1704135991526,"execution_millis":662088,"deepnote_to_be_reexecuted":false,"cell_id":"db0b6ff811ce45c1ad599670fba5cdf3","deepnote_cell_type":"code"},"source":"!pip install cython\n# Install pycocotools, the version by default in Colab\n# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n\n# Download TorchVision repo to use some files from\n# references/detection\n!git clone https://github.com/pytorch/vision.git\n!cd vision && git checkout v0.3.0\n!cp vision/references/detection/utils.py ./\n!cp vision/references/detection/transforms.py ./\n!cp vision/references/detection/coco_eval.py ./\n!cp vision/references/detection/engine.py ./\n!cp vision/references/detection/coco_utils.py ./\n\n# Imports\nimport fnmatch\nimport json\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image\n\nycb = [\n    \"003_cracker_box.sdf\",\n    \"004_sugar_box.sdf\",\n    \"005_tomato_soup_can.sdf\",\n    \"006_mustard_bottle.sdf\",\n    \"009_gelatin_box.sdf\",\n    \"010_potted_meat_can.sdf\",\n]\n\n# drake_reserved_labels = [32765, 32764, 32766, 32767]\n\n\ndef colorize_labels(image):\n    \"\"\"Colorizes labels.\"\"\"\n    cc = mpl.colors.ColorConverter()\n    color_cycle = plt.rcParams[\"axes.prop_cycle\"]\n    colors = np.array([cc.to_rgb(c[\"color\"]) for c in color_cycle])\n    bg_color = [0, 0, 0]\n    image = np.squeeze(image)\n    background = np.zeros(image.shape[:2], dtype=bool)\n    for label in reserved_labels:\n        background |= image == int(label)\n    image[np.logical_not(background)]\n    color_image = colors[image % len(colors)]\n    color_image[background] = bg_color\n    return color_image","block_group":"c8649fea5aef48cc9ba7de490951fddc","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-3d77kp5k\n  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-3d77kp5k\n  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.7)\nRequirement already satisfied: matplotlib>=2.1.0 in /usr/lib/python3/dist-packages (from pycocotools==2.0) (3.5.1)\nRequirement already satisfied: setuptools>=18.0 in /usr/lib/python3/dist-packages (from pycocotools==2.0) (59.6.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[66 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m running bdist_wheel\n  \u001b[31m   \u001b[0m running build\n  \u001b[31m   \u001b[0m running build_py\n  \u001b[31m   \u001b[0m creating build\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m copying pycocotools/coco.py -> build/lib.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m copying pycocotools/mask.py -> build/lib.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m running build_ext\n  \u001b[31m   \u001b[0m Compiling pycocotools/_mask.pyx because it changed.\n  \u001b[31m   \u001b[0m [1/1] Cythonizing pycocotools/_mask.pyx\n  \u001b[31m   \u001b[0m /usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /tmp/pip-req-build-3d77kp5k/PythonAPI/pycocotools/_mask.pyx\n  \u001b[31m   \u001b[0m   tree = Parsing.p_module(s, pxd, full_module_name)\n  \u001b[31m   \u001b[0m building 'pycocotools._mask' extension\n  \u001b[31m   \u001b[0m creating build/common\n  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10\n  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/pycocotools\n  \u001b[31m   \u001b[0m x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.10/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleDecode’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:46:7: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n  \u001b[31m   \u001b[0m       |       ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:46:49: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n  \u001b[31m   \u001b[0m       |                                                 ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrPoly’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:166:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n  \u001b[31m   \u001b[0m       |   ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:166:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n  \u001b[31m   \u001b[0m       |                                                      ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c:167:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n  \u001b[31m   \u001b[0m       |   ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:167:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n  \u001b[31m   \u001b[0m       |                                                      ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleToString’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:212:7: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n  \u001b[31m   \u001b[0m       |       ^~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:212:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n  \u001b[31m   \u001b[0m       |                           ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrString’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:220:3: warning: this ‘while’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n  \u001b[31m   \u001b[0m       |   ^~~~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:220:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘while’\n  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n  \u001b[31m   \u001b[0m       |                      ^~~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:228:5: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n  \u001b[31m   \u001b[0m       |     ^~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:228:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n  \u001b[31m   \u001b[0m       |                                  ^~~~\n  \u001b[31m   \u001b[0m x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n  \u001b[31m   \u001b[0m pycocotools/_mask.c:47:10: fatal error: Python.h: No such file or directory\n  \u001b[31m   \u001b[0m    47 | #include \"Python.h\"\n  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n  \u001b[31m   \u001b[0m compilation terminated.\n  \u001b[31m   \u001b[0m error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[31m  ERROR: Failed building wheel for pycocotools\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for pycocotools\nFailed to build pycocotools\nInstalling collected packages: pycocotools\n  Running setup.py install for pycocotools ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pycocotools\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m running install\n  \u001b[31m   \u001b[0m /usr/lib/python3/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n  \u001b[31m   \u001b[0m   warnings.warn(\n  \u001b[31m   \u001b[0m running build\n  \u001b[31m   \u001b[0m running build_py\n  \u001b[31m   \u001b[0m running build_ext\n  \u001b[31m   \u001b[0m building 'pycocotools._mask' extension\n  \u001b[31m   \u001b[0m x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.10/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleDecode’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:46:7: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n  \u001b[31m   \u001b[0m       |       ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:46:49: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m    46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n  \u001b[31m   \u001b[0m       |                                                 ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrPoly’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:166:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n  \u001b[31m   \u001b[0m       |   ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:166:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m   166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n  \u001b[31m   \u001b[0m       |                                                      ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c:167:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n  \u001b[31m   \u001b[0m       |   ^~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:167:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n  \u001b[31m   \u001b[0m   167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n  \u001b[31m   \u001b[0m       |                                                      ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleToString’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:212:7: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n  \u001b[31m   \u001b[0m       |       ^~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:212:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n  \u001b[31m   \u001b[0m   212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n  \u001b[31m   \u001b[0m       |                           ^\n  \u001b[31m   \u001b[0m ../common/maskApi.c: In function ‘rleFrString’:\n  \u001b[31m   \u001b[0m ../common/maskApi.c:220:3: warning: this ‘while’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n  \u001b[31m   \u001b[0m       |   ^~~~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:220:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘while’\n  \u001b[31m   \u001b[0m   220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n  \u001b[31m   \u001b[0m       |                      ^~~~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:228:5: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n  \u001b[31m   \u001b[0m       |     ^~\n  \u001b[31m   \u001b[0m ../common/maskApi.c:228:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n  \u001b[31m   \u001b[0m   228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n  \u001b[31m   \u001b[0m       |                                  ^~~~\n  \u001b[31m   \u001b[0m x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n  \u001b[31m   \u001b[0m pycocotools/_mask.c:47:10: fatal error: Python.h: No such file or directory\n  \u001b[31m   \u001b[0m    47 | #include \"Python.h\"\n  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~\n  \u001b[31m   \u001b[0m compilation terminated.\n  \u001b[31m   \u001b[0m error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while trying to install package.\n\u001b[31m╰─>\u001b[0m pycocotools\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for output from the failure.\nCloning into 'vision'...\nremote: Enumerating objects: 450358, done.\u001b[K\nremote: Counting objects: 100% (30820/30820), done.\u001b[K\nremote: Compressing objects: 100% (1450/1450), done.\u001b[K\nremote: Total 450358 (delta 29392), reused 30705 (delta 29323), pack-reused 419538\u001b[K\nReceiving objects: 100% (450358/450358), 886.57 MiB | 11.09 MiB/s, done.\nResolving deltas: 100% (418477/418477), done.\nUpdating files: 100% (866/866), done.\nUpdating files: 100% (890/890), done.\nNote: switching to 'v0.3.0'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at be376084d8 version check against PyTorch's CUDA version\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"XwyE5A8DGtct","cell_id":"2f63be6a9e9c4885ae8e184a8745aae1","deepnote_cell_type":"markdown"},"source":"# Download our bin-picking dataset\n\nIt's definitely possible to actually create this dataset on Colab; I've just written a version of the \"clutter_gen\" method from the last chapter that writes the images (and label images) to disk, along with some annotations.  But it takes a non-trivial amount of time to generate 10,000 images. \n","block_group":"6ce7aff95cfe44c4bf21b73e63252e35"},{"cell_type":"code","metadata":{"id":"_DgAgqauIET9","source_hash":null,"execution_start":1704136653611,"execution_millis":680,"deepnote_to_be_reexecuted":false,"cell_id":"59b31cf8279040b08f8de24875bd28bc","deepnote_cell_type":"code"},"source":"dataset_path = \"clutter_maskrcnn_data\"\nif not os.path.exists(dataset_path):\n    !wget https://groups.csail.mit.edu/locomotion/clutter_maskrcnn_data.zip .\n    !unzip -q clutter_maskrcnn_data.zip","block_group":"4cc8a5472ae0418fb15ee76560aeccbb","execution_count":null,"outputs":[{"name":"stdout","text":"--2024-01-01 19:17:33--  https://groups.csail.mit.edu/locomotion/clutter_maskrcnn_data.zip\nResolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\nConnecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:443... connected.\nHTTP request sent, awaiting response... 403 Forbidden\n2024-01-01 19:17:33 ERROR 403: Forbidden.\n\n--2024-01-01 19:17:33--  http://./\nResolving . (.)... failed: No address associated with hostname.\nwget: unable to resolve host address ‘.’\nunzip:  cannot find or open clutter_maskrcnn_data.zip, clutter_maskrcnn_data.zip.zip or clutter_maskrcnn_data.zip.ZIP.\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"xA8sBvuHNNH1","cell_id":"a6beb664c79144c59d230721caeeb266","deepnote_cell_type":"markdown"},"source":"If you are on colab, go ahead and use the file browser on the left (looks like a drive under the table of contents panel) to click through the .png and .json files to make sure you understand the dataset you've just created!  If you're on a local machine, just browse to the folder.","block_group":"0d5347f561214ed6b41f77076c0de19b"},{"cell_type":"markdown","metadata":{"id":"C9Ee5NV54Dmj","cell_id":"f1fcf25eca59480ebbaf027e34305757","deepnote_cell_type":"markdown"},"source":"# Teach pytorch how to load the dataset\n\ninto the [format expected by Mask R-CNN](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn).","block_group":"9ab8519a4e054bc8a5935a67b8567601"},{"cell_type":"code","metadata":{"id":"mTgWtixZTs3X","cell_id":"562c690900bc4e36bd41cbea8503eacc","deepnote_cell_type":"code"},"source":"class BinPickingDataset(torch.utils.data.Dataset):\n    def __init__(self, root, transforms=None):\n        self.root = root\n        self.num_images = len(fnmatch.filter(os.listdir(root), \"*.png\"))\n        self.transforms = transforms\n\n    def __getitem__(self, idx):\n        filename_base = os.path.join(self.root, f\"{idx:05d}\")\n\n        img = Image.open(filename_base + \".png\").convert(\"RGB\")\n        mask = np.squeeze(np.load(filename_base + \"_mask.npy\"))\n\n        with open(filename_base + \".json\", \"r\") as f:\n            instance_id_to_class_name = json.load(f)\n        labels = ycb == instance_id_to_class_name\n\n        # instances are encoded as different colors\n        obj_ids = np.asarray(list(instance_id_to_class_name.keys()))\n        count = (mask == np.int16(obj_ids)[:, None, None]).sum(axis=2).sum(axis=1)\n\n        # discard objects instances with less than 10 pixels\n        obj_ids = obj_ids[count >= 10]\n\n        labels = [ycb.index(instance_id_to_class_name[id] + \".sdf\") for id in obj_ids]\n        obj_ids = np.int16(np.asarray(obj_ids))\n\n        # split the color-encoded mask into a set of binary masks\n        masks = mask == obj_ids[:, None, None]\n\n        # get bounding box coordinates for each mask\n        num_objs = len(obj_ids)\n        boxes = []\n        for i in range(num_objs):\n            pos = np.where(masks[i])\n            xmin = np.min(pos[1])\n            xmax = np.max(pos[1])\n            ymin = np.min(pos[0])\n            ymax = np.max(pos[0])\n            boxes.append([xmin, ymin, xmax, ymax])\n\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"masks\"] = masks\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return self.num_images","block_group":"9bb0a851f71a436bb119aae9424a6aa5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J6f3ZOTJ4Km9","cell_id":"65a3a04c9acd4ab792abd609124c8ddb","deepnote_cell_type":"markdown"},"source":"Let's check the output of our dataset.","block_group":"e3f5b69b43404d959b831bed46d32aa1"},{"cell_type":"code","metadata":{"id":"ZEARO4B_ye0s","cell_id":"0c2d796b1556495088a345ee38d2bc42","deepnote_cell_type":"code"},"source":"dataset = BinPickingDataset(dataset_path)\ndataset[0][0]","block_group":"717fd3afc63c4aa9acb20e5cad8f63b7","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xWA2NXwVhV_C","cell_id":"9df3f899b87b4fcc8e2fcc5ed41225ea","deepnote_cell_type":"markdown"},"source":"# Define the network\n\nThis cell is where the magic begins to happen.  We load a network that is pre-trained on the COCO dataset, then replace the network head with a new (untrained) network with the right number of outputs for our YCB recognition/segmentation task.","block_group":"5600fd1ff8f04ff7a74a044f55a7dc59"},{"cell_type":"code","metadata":{"id":"YjNHjVMOyYlH","cell_id":"82ac6810bc8b483c967427856648c891","deepnote_cell_type":"code"},"source":"import torchvision\nfrom torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\n\ndef get_instance_segmentation_model(num_classes):\n    # load an instance segmentation model pre-trained on COCO\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(\n        weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n    )\n\n    # get the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n        in_features_mask, hidden_layer, num_classes\n    )\n\n    return model","block_group":"59373910902543a6955b9adc43780283","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WXLwePV5ieP","cell_id":"013ef1a17b684c3aa3a7be10aee687dc","deepnote_cell_type":"markdown"},"source":"That's it, this will make model be ready to be trained and evaluated on our custom dataset.\n\n# Transforms\n\nLet's write some helper functions for data augmentation / transformation, which leverages the functions in torchvision `refereces/detection`. \n","block_group":"d3501fe6645543c2a809816aff7ba227"},{"cell_type":"code","metadata":{"id":"l79ivkwKy357","cell_id":"c9d0574a0de745438891eb58920ad643","deepnote_cell_type":"code"},"source":"import transforms as T\nimport utils\nfrom engine import evaluate, train_one_epoch\n\n\ndef get_transform(train):\n    transforms = []\n    # converts the image, a PIL image, into a PyTorch Tensor\n    transforms.append(T.ToTensor())\n    if train:\n        # during training, randomly flip the training images\n        # and ground-truth for data augmentation\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","block_group":"a86fff81985148849a16beda4dba9dff","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FzCLqiZk-sjf","cell_id":"8496dbed236a4b5ab74ab188523bcb0a","deepnote_cell_type":"markdown"},"source":"Note that we do not need to add a mean/std normalization nor image rescaling in the data transforms, as those are handled internally by the Mask R-CNN model.","block_group":"07b9c7107a3042849dc19fec3f35aaf7"},{"cell_type":"markdown","metadata":{"id":"3YFJGJxk6XEs","cell_id":"74616182cf8e42d287789463dfd8dc87","deepnote_cell_type":"markdown"},"source":"# Putting everything together\n\nWe now have the dataset class, the models and the data transforms. Let's instantiate them","block_group":"5baee4e7ebfc443588f9724f2536f284"},{"cell_type":"code","metadata":{"id":"a5dGaIezze3y","cell_id":"418058f5ca134bbaa918520c21d55988","deepnote_cell_type":"code"},"source":"# use our dataset and defined transformations\ndataset = BinPickingDataset(dataset_path, get_transform(train=True))\ndataset_test = BinPickingDataset(dataset_path, get_transform(train=False))\n\n# split the dataset in train and test set\ntorch.manual_seed(1)\nindices = torch.randperm(len(dataset)).tolist()\ndataset = torch.utils.data.Subset(dataset, indices[:-50])\ndataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n\n# define training and validation data loaders\ndata_loader = torch.utils.data.DataLoader(\n    dataset,\n    batch_size=2,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=utils.collate_fn,\n)\n\ndata_loader_test = torch.utils.data.DataLoader(\n    dataset_test,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=utils.collate_fn,\n)","block_group":"aeda8344e04e495b9f91209f38e1057b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5yvZUprj4ZN","cell_id":"f8807be407894b6696d9416fe86b6bd1","deepnote_cell_type":"markdown"},"source":"Now let's instantiate the model and the optimizer","block_group":"f9a0d66aefe54c1fbfaf343ae5741ee1"},{"cell_type":"code","metadata":{"id":"zoenkCj18C4h","cell_id":"92feb7c59eb040c984be49b5202dc354","deepnote_cell_type":"code"},"source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\nnum_classes = len(ycb) + 1\n\n# get the model using our helper function\nmodel = get_instance_segmentation_model(num_classes)\n# move model to the right device\nmodel.to(device)\n\n# construct an optimizer\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n\n# and a learning rate scheduler which decreases the learning rate by\n# 10x every 3 epochs\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","block_group":"25ee25943af54519aa53688a4a17f4a4","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XAd56lt4kDxc","cell_id":"55f0003f95434747b333fd555ee7c6d3","deepnote_cell_type":"markdown"},"source":"And now let's train the model for 10 epochs, evaluating at the end of every epoch.","block_group":"b0c6b4c2aa9540acb942ce790c4b2e5e"},{"cell_type":"code","metadata":{"id":"at-h4OWK0aoc","cell_id":"bce71d9f8ed141da84a85db7f242420b","deepnote_cell_type":"code"},"source":"# let's train it for 10 epochs\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    # train for one epoch, printing every 10 iterations\n    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n    # update the learning rate\n    lr_scheduler.step()\n    # evaluate on the test dataset\n    evaluate(model, data_loader_test, device=device)","block_group":"12348b2b135645b49131ed5a0f378482","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXTyZhCScUTI","cell_id":"caaac280f58a486a80d3919425a24eae","deepnote_cell_type":"markdown"},"source":"If you're going to leave this running for a bit, I recommend scheduling the following cell to run immediately (so that you don't lose your work).","block_group":"64419e7a650c400287bf27bae42cbce7"},{"cell_type":"code","metadata":{"id":"vUJXn15pGzRj","cell_id":"6834469cfbb94c3396bbc547f64938b6","deepnote_cell_type":"code"},"source":"torch.save(model.state_dict(), \"clutter_maskrcnn_model.pt\")\n\nfrom google.colab import files\n\nfiles.download(\"clutter_maskrcnn_model.pt\")","block_group":"398d4722437a407b9a92523a60d7b9bc","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6mYGFLxkO8F","cell_id":"0dd724d8b1a94436b81ba10dbf8b3fcb","deepnote_cell_type":"markdown"},"source":"Now that training has finished, let's have a look at what it actually predicts in a test image","block_group":"889ec4f74d5042f8b86ac4f8cd0bdd7f"},{"cell_type":"code","metadata":{"id":"YHwIdxH76uPj","cell_id":"0067dd87f3af44f4b91f99c98a78ed7d","deepnote_cell_type":"code"},"source":"# pick one image from the test set\nimg, _ = dataset_test[0]\n# put the model in evaluation mode\nmodel.eval()\nwith torch.no_grad():\n    prediction = model([img.to(device)])","block_group":"1c95aa5067f1496a8f108de005d4a37a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DmN602iKsuey","cell_id":"17cfb2ac44144b2cbc45e35987be1851","deepnote_cell_type":"markdown"},"source":"Printing the prediction shows that we have a list of dictionaries. Each element of the list corresponds to a different image. As we have a single image, there is a single dictionary in the list.\nThe dictionary contains the predictions for the image we passed. In this case, we can see that it contains `boxes`, `labels`, `masks` and `scores` as fields.","block_group":"e199724cd4414ea3a1210b0a74a3397f"},{"cell_type":"code","metadata":{"id":"Lkmb3qUu6zw3","cell_id":"56cf2fa39d0e4b1e8d7f3928cb654a16","deepnote_cell_type":"code"},"source":"prediction","block_group":"d63d4b355c6c44ffa459727db70c25a0","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RwT21rzotFbH","cell_id":"ef8cf31fc9194164963aa062608f2106","deepnote_cell_type":"markdown"},"source":"Let's inspect the image and the predicted segmentation masks.\n\nFor that, we need to convert the image, which has been rescaled to 0-1 and had the channels flipped so that we have it in `[C, H, W]` format.","block_group":"d2bbc937335549acab494e346c44f80b"},{"cell_type":"code","metadata":{"id":"bpqN9t1u7B2J","cell_id":"e783a84560b245e38359287c6777102e","deepnote_cell_type":"code"},"source":"Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())","block_group":"f11260216d004f80a0203ff666c51d04","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M58J3O9OtT1G","cell_id":"d45fc28b035746f2bd007b9825c24ed4","deepnote_cell_type":"markdown"},"source":"And let's now visualize the top predicted segmentation mask. The masks are predicted as `[N, 1, H, W]`, where `N` is the number of predictions, and are probability maps between 0-1.","block_group":"783c976b0d1e4cd88689eca31fec0c40"},{"cell_type":"code","metadata":{"id":"5v5S3bm07SO1","cell_id":"59307268213846729d7d1dc9b8f3a051","deepnote_cell_type":"code"},"source":"Image.fromarray(prediction[0][\"masks\"][0, 0].mul(255).byte().cpu().numpy())","block_group":"8e2a4b72ef8b46bc8fd873baa23bf0ed","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=cd3e7d17-0c32-40f9-b7c9-aa7a4e2fa280' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clutter_maskrcnn_train.ipynb","provenance":[],"toc_visible":true,"collapsed_sections":[]},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3.10.8 64-bit"},"accelerator":"GPU","language_info":{"name":"python","version":"3.10.8","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"ae0912444fa24cc6bafc64074fbf08fe","deepnote_persisted_session":{"createdAt":"2024-01-01T19:17:42.425Z"},"deepnote_execution_queue":[]}}